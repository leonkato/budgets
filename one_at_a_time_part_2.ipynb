{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add feature engineering one piece at a time and monitor performance.  This notebook goes through all but the last model.\n",
    "\n",
    "| model | agg. log loss  |  agg. F1 score |  comment\n",
    "|-------|:--------------:|:--------------:|----------\n",
    "|mod3_1 |  0.0573        |   0.982        | text features only, add bigrams\n",
    "|mod3_1a|  0.0593        |   0.982        | text features only, add bigrams, add scaler\n",
    "|mod3_2 |  0.305         |   0.900        | same, but reduce to 300 features using SelectKBest\n",
    "|mod3_2a|  0.0798        |   0.976        | same, but reduce to 3000 features using SelectKBest\n",
    "|mod3_2b|  0.0589        |   0.982        | same, but reduce to 15000 features using SelectKBest\n",
    "|mod3_3 |  0.0580        |   0.982        | same, but reduce to 15000 features using SelectKBest\n",
    "\n",
    "#### Best competition score was mod3_1; none of the feature selections helped, though some were close.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add the other feature engineering/modeling techniques starting with mod_1_1_1\n",
    "\n",
    "We're starting here because this has better performance that all 5 models in the tutorial.  \n",
    "\n",
    "Start with mod1_1_1\n",
    "* mod1_1_1 - substitute zeros for numerical features (work-around for n_jobs bug), default CountVectorizer.\n",
    "\n",
    "* __mod3_1 is best so far: log loss on training set: 0.0467, log loss on test set: 0.0573; Average F1 and accuracy all targets : 0.982.  Competition score: 0.6599.__\n",
    "\n",
    "\n",
    "Add the following:\n",
    "* text features\n",
    "    * in count_vectorizer: ngram_range=(1, 2) - improves model performance significantly but doubles fitting time.  The feature set goes from 3.6k tokens to 31k features (tokens + bigrams).\n",
    "    * SelectKBest(chi2, chi_k)\n",
    "* scale with MaxAbsScaler\n",
    "* reduce dimensions\n",
    "    * selectKbest - 300 features\n",
    "    * selectKbest - 1000 features\n",
    "    * selectKbest - 15000 features\n",
    "    * SelectFromModel(RandomForest) - - 15000 features\n",
    "    \n",
    "Summary: Reducing the features doesn't help.  The more features you keep, the better the classification.  It does seem that the real motivation for reducing size of the feature set is to limit the number of features to combine for feature interaction in the next step.  \n",
    "\n",
    "* add feature interaction with sparse_interaction - see next notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imports/setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "pd.set_option('display.max_columns', 60)\n",
    "\n",
    "from timeit import default_timer as timer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score, accuracy_score, classification_report\n",
    "\n",
    "import python.flat_to_labels as ftl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from python.dd_mmll import multi_multi_log_loss, BOX_PLOTS_COLUMN_INDICES\n",
    "BPCI = BOX_PLOTS_COLUMN_INDICES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from python.multilabel import multilabel_train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for the pipeline\n",
    "from sklearn.pipeline import Pipeline\n",
    "# for the selectors\n",
    "from sklearn.preprocessing import FunctionTransformer, StandardScaler, MaxAbsScaler\n",
    "# for gluing preprocessed text and numbers together\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "# for nans in the numeric data\n",
    "from sklearn.preprocessing import Imputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import classifiers\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Import CountVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "# feature selection\n",
    "from sklearn.feature_selection import SelectFromModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get data\n",
    "df = pd.read_csv('data/TrainingData.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Function</th>\n",
       "      <th>Use</th>\n",
       "      <th>Sharing</th>\n",
       "      <th>Reporting</th>\n",
       "      <th>Student_Type</th>\n",
       "      <th>Position_Type</th>\n",
       "      <th>Object_Type</th>\n",
       "      <th>Pre_K</th>\n",
       "      <th>Operating_Status</th>\n",
       "      <th>Object_Description</th>\n",
       "      <th>Text_2</th>\n",
       "      <th>SubFund_Description</th>\n",
       "      <th>Job_Title_Description</th>\n",
       "      <th>Text_3</th>\n",
       "      <th>Text_4</th>\n",
       "      <th>Sub_Object_Description</th>\n",
       "      <th>Location_Description</th>\n",
       "      <th>FTE</th>\n",
       "      <th>Function_Description</th>\n",
       "      <th>Facility_or_Department</th>\n",
       "      <th>Position_Extra</th>\n",
       "      <th>Total</th>\n",
       "      <th>Program_Description</th>\n",
       "      <th>Fund_Description</th>\n",
       "      <th>Text_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>134338</th>\n",
       "      <td>Teacher Compensation</td>\n",
       "      <td>Instruction</td>\n",
       "      <td>School Reported</td>\n",
       "      <td>School</td>\n",
       "      <td>NO_LABEL</td>\n",
       "      <td>Teacher</td>\n",
       "      <td>NO_LABEL</td>\n",
       "      <td>NO_LABEL</td>\n",
       "      <td>PreK-12 Operating</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Teacher-Elementary</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>KINDERGARTEN</td>\n",
       "      <td>50471.810</td>\n",
       "      <td>KINDERGARTEN</td>\n",
       "      <td>General Fund</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206341</th>\n",
       "      <td>NO_LABEL</td>\n",
       "      <td>NO_LABEL</td>\n",
       "      <td>NO_LABEL</td>\n",
       "      <td>NO_LABEL</td>\n",
       "      <td>NO_LABEL</td>\n",
       "      <td>NO_LABEL</td>\n",
       "      <td>NO_LABEL</td>\n",
       "      <td>NO_LABEL</td>\n",
       "      <td>Non-Operating</td>\n",
       "      <td>CONTRACTOR SERVICES</td>\n",
       "      <td>BOND EXPENDITURES</td>\n",
       "      <td>BUILDING FUND</td>\n",
       "      <td>(blank)</td>\n",
       "      <td>Regular</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>RGN  GOB</td>\n",
       "      <td>NaN</td>\n",
       "      <td>UNDESIGNATED</td>\n",
       "      <td>3477.860</td>\n",
       "      <td>BUILDING IMPROVEMENT SERVICES</td>\n",
       "      <td>NaN</td>\n",
       "      <td>BUILDING IMPROVEMENT SERVICES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>326408</th>\n",
       "      <td>Teacher Compensation</td>\n",
       "      <td>Instruction</td>\n",
       "      <td>School Reported</td>\n",
       "      <td>School</td>\n",
       "      <td>Unspecified</td>\n",
       "      <td>Teacher</td>\n",
       "      <td>Base Salary/Compensation</td>\n",
       "      <td>Non PreK</td>\n",
       "      <td>PreK-12 Operating</td>\n",
       "      <td>Personal Services - Teachers</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>TCHER 2ND GRADE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Regular Instruction</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>TEACHER</td>\n",
       "      <td>62237.130</td>\n",
       "      <td>Instruction - Regular</td>\n",
       "      <td>General Purpose School</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>364634</th>\n",
       "      <td>Substitute Compensation</td>\n",
       "      <td>Instruction</td>\n",
       "      <td>School Reported</td>\n",
       "      <td>School</td>\n",
       "      <td>Unspecified</td>\n",
       "      <td>Substitute</td>\n",
       "      <td>Benefits</td>\n",
       "      <td>NO_LABEL</td>\n",
       "      <td>PreK-12 Operating</td>\n",
       "      <td>EMPLOYEE BENEFITS</td>\n",
       "      <td>TEACHER SUBS</td>\n",
       "      <td>GENERAL FUND</td>\n",
       "      <td>Teacher, Short Term Sub</td>\n",
       "      <td>Regular</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>UNALLOC BUDGETS/SCHOOLS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PROFESSIONAL-INSTRUCTIONAL</td>\n",
       "      <td>22.300</td>\n",
       "      <td>GENERAL MIDDLE/JUNIOR HIGH SCH</td>\n",
       "      <td>NaN</td>\n",
       "      <td>REGULAR INSTRUCTION</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47683</th>\n",
       "      <td>Substitute Compensation</td>\n",
       "      <td>Instruction</td>\n",
       "      <td>School Reported</td>\n",
       "      <td>School</td>\n",
       "      <td>Unspecified</td>\n",
       "      <td>Teacher</td>\n",
       "      <td>Substitute Compensation</td>\n",
       "      <td>NO_LABEL</td>\n",
       "      <td>PreK-12 Operating</td>\n",
       "      <td>TEACHER COVERAGE FOR TEACHER</td>\n",
       "      <td>TEACHER SUBS</td>\n",
       "      <td>GENERAL FUND</td>\n",
       "      <td>Teacher, Secondary (High)</td>\n",
       "      <td>Alternative</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NON-PROJECT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PROFESSIONAL-INSTRUCTIONAL</td>\n",
       "      <td>54.166</td>\n",
       "      <td>GENERAL HIGH SCHOOL EDUCATION</td>\n",
       "      <td>NaN</td>\n",
       "      <td>REGULAR INSTRUCTION</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Function          Use          Sharing Reporting  \\\n",
       "134338     Teacher Compensation  Instruction  School Reported    School   \n",
       "206341                 NO_LABEL     NO_LABEL         NO_LABEL  NO_LABEL   \n",
       "326408     Teacher Compensation  Instruction  School Reported    School   \n",
       "364634  Substitute Compensation  Instruction  School Reported    School   \n",
       "47683   Substitute Compensation  Instruction  School Reported    School   \n",
       "\n",
       "       Student_Type Position_Type               Object_Type     Pre_K  \\\n",
       "134338     NO_LABEL       Teacher                  NO_LABEL  NO_LABEL   \n",
       "206341     NO_LABEL      NO_LABEL                  NO_LABEL  NO_LABEL   \n",
       "326408  Unspecified       Teacher  Base Salary/Compensation  Non PreK   \n",
       "364634  Unspecified    Substitute                  Benefits  NO_LABEL   \n",
       "47683   Unspecified       Teacher   Substitute Compensation  NO_LABEL   \n",
       "\n",
       "         Operating_Status            Object_Description             Text_2  \\\n",
       "134338  PreK-12 Operating                           NaN                NaN   \n",
       "206341      Non-Operating           CONTRACTOR SERVICES  BOND EXPENDITURES   \n",
       "326408  PreK-12 Operating  Personal Services - Teachers                NaN   \n",
       "364634  PreK-12 Operating             EMPLOYEE BENEFITS       TEACHER SUBS   \n",
       "47683   PreK-12 Operating  TEACHER COVERAGE FOR TEACHER       TEACHER SUBS   \n",
       "\n",
       "       SubFund_Description       Job_Title_Description       Text_3  \\\n",
       "134338                 NaN         Teacher-Elementary           NaN   \n",
       "206341       BUILDING FUND                     (blank)      Regular   \n",
       "326408                 NaN             TCHER 2ND GRADE          NaN   \n",
       "364634        GENERAL FUND    Teacher, Short Term Sub       Regular   \n",
       "47683         GENERAL FUND  Teacher, Secondary (High)   Alternative   \n",
       "\n",
       "                     Text_4 Sub_Object_Description Location_Description  FTE  \\\n",
       "134338                  NaN                    NaN                  NaN  1.0   \n",
       "206341                  NaN                    NaN                  NaN  NaN   \n",
       "326408  Regular Instruction                    NaN                  NaN  1.0   \n",
       "364634                  NaN                    NaN                  NaN  NaN   \n",
       "47683                   NaN                    NaN                  NaN  NaN   \n",
       "\n",
       "           Function_Description Facility_or_Department  \\\n",
       "134338                      NaN                    NaN   \n",
       "206341                 RGN  GOB                    NaN   \n",
       "326408                      NaN                    NaN   \n",
       "364634  UNALLOC BUDGETS/SCHOOLS                    NaN   \n",
       "47683               NON-PROJECT                    NaN   \n",
       "\n",
       "                    Position_Extra      Total             Program_Description  \\\n",
       "134338               KINDERGARTEN   50471.810                    KINDERGARTEN   \n",
       "206341                UNDESIGNATED   3477.860   BUILDING IMPROVEMENT SERVICES   \n",
       "326408                     TEACHER  62237.130           Instruction - Regular   \n",
       "364634  PROFESSIONAL-INSTRUCTIONAL     22.300  GENERAL MIDDLE/JUNIOR HIGH SCH   \n",
       "47683   PROFESSIONAL-INSTRUCTIONAL     54.166   GENERAL HIGH SCHOOL EDUCATION   \n",
       "\n",
       "              Fund_Description                         Text_1  \n",
       "134338            General Fund                            NaN  \n",
       "206341                     NaN  BUILDING IMPROVEMENT SERVICES  \n",
       "326408  General Purpose School                            NaN  \n",
       "364634                     NaN            REGULAR INSTRUCTION  \n",
       "47683                      NaN            REGULAR INSTRUCTION  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# take a look\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Encode the targets as categorical variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Function            category\n",
      "Object_Type         category\n",
      "Operating_Status    category\n",
      "Position_Type       category\n",
      "Pre_K               category\n",
      "Reporting           category\n",
      "Sharing             category\n",
      "Student_Type        category\n",
      "Use                 category\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "### bind variable LABELS - these are actually the targets and we're going to one-hot encode them...\n",
    "LABELS = ['Function',  'Use',  'Sharing',  'Reporting',  'Student_Type',  'Position_Type', \n",
    "          'Object_Type',  'Pre_K',  'Operating_Status']\n",
    "\n",
    "### This turns out to be key.  Submission requires the dummy versions of these vars to be in this order.\n",
    "LABELS.sort()\n",
    "\n",
    "# Define the lambda function: categorize_label\n",
    "categorize_label = lambda x: x.astype('category')\n",
    "\n",
    "# Convert df[LABELS] to a categorical type\n",
    "df[LABELS] = df[LABELS].apply(categorize_label, axis=0)\n",
    "\n",
    "# Print the converted dtypes\n",
    "print(df[LABELS].dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Let's save the unique labels for each output (category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build a dictionary\n",
    "the_labels = {col : df[col].unique().tolist() for col in df[LABELS].columns}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Instruction',\n",
       " 'NO_LABEL',\n",
       " 'O&M',\n",
       " 'Pupil Services & Enrichment',\n",
       " 'ISPD',\n",
       " 'Leadership',\n",
       " 'Business Services',\n",
       " 'Untracked Budget Set-Aside']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "the_labels['Use']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Show metrics for each target and average for all targets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def report_f1(true, pred):\n",
    "    the_scores = []\n",
    "    for target in range(len(LABELS)):\n",
    "        the_score = f1_score(true[:, target], pred[:, target], average='weighted')\n",
    "        print('F1 score for target {}: {:.3f}'.format(LABELS[target], the_score))\n",
    "        the_scores.append(the_score)\n",
    "    print('Average F1 score for all targets : {:.3f}'.format(np.mean(the_scores)))\n",
    "\n",
    "def report_accuracy(true, pred):\n",
    "    the_scores = []\n",
    "    for target in range(len(LABELS)):\n",
    "        the_score = accuracy_score(true[:, target], pred[:, target])\n",
    "        print('Accuracy score for target {}: {:.3f}'.format(LABELS[target], the_score))\n",
    "        the_scores.append(the_score)\n",
    "    print('Average accuracy score for all targets : {:.3f}'.format(np.mean(the_scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Log loss\n",
    "\n",
    "I want to see the aggregate log loss, but also need the values for each target. It works a bit differently for log_loss because log_loss uses the probability predictions and wants the true labels in binarized format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LABELS = ['Function', 'Object_Type','Operating_Status', 'Position_Type', 'Pre_K', \n",
    "#           'Reporting','Sharing', 'Student_Type','Use']\n",
    "# BPCI is the slices that get the columns associated with LABELS, i.e.\n",
    "#          [slice(0, 37, None), slice(37, 48, None), slice(48, 51, None), slice(51, 76, None), slice(76, 79, None), \n",
    "#           slice(79, 82, None), slice(82, 87, None), slice(87, 96, None), slice(96, 104, None)]\n",
    "\n",
    "# grab the columns for each target - that's in BPCI indexed by position in LABELS\n",
    "# normalize so probabilities sum to one (unless sum is zero, then we clip)\n",
    "\n",
    "BCPI=BOX_PLOTS_COLUMN_INDICES\n",
    "\n",
    "def norm_probs(probs, indices=BPCI, targets = LABELS):\n",
    "    ''' input:  array n_samples, 104 ; output: array n_samples, 104 \n",
    "         normalized within target columns such that for each target, the sum of probabilities for each row is 1'''\n",
    "    # make a copy; don't want to smash the input\n",
    "    lprobs = np.copy(probs)\n",
    "    for i, targ in enumerate(targets):\n",
    "        lprobs[:, indices[i]] /=  np.clip(np.sum(lprobs[:, indices[i]], axis=1, keepdims=True), 1e-15, np.inf)\n",
    "    return lprobs\n",
    "\n",
    "from sklearn.metrics import log_loss\n",
    "def report_log_loss(true, pred):\n",
    "    ''' Takes true in binarized format.  Both args are shape (n_samples, 104)'''\n",
    "    the_scores = []\n",
    "    # note: BPCI[idx] is the slice that gets the right columns for each target\n",
    "    # first normalize probabilities within targets \n",
    "    normed_probas = norm_probs(pred)\n",
    "    the_scores = []\n",
    "    for idx, target in enumerate(LABELS):\n",
    "        the_score = log_loss(true[:, BPCI[idx]], pred[:, BPCI[idx]])\n",
    "        print('log loss for target {}: {:.3f}'.format(target, the_score))\n",
    "        the_scores.append(the_score)\n",
    "    print('Average log_loss for all targets : {:.3f}'.format(np.mean(the_scores))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUMERIC_COLUMNS = ['FTE', 'Total']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get labels and convert to dummy variables: label_dummies\n",
    "label_dummies = pd.get_dummies(df[LABELS])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add text processing to the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define combine_text_columns()\n",
    "def combine_text_columns(df, to_drop=NUMERIC_COLUMNS + LABELS):\n",
    "    \"\"\" converts all text columns in each row of df to single string \"\"\"\n",
    "    # Drop non-text columns that are in the df\n",
    "    to_drop = set(to_drop) & set(df.columns.tolist())\n",
    "    text_data = df.drop(to_drop, axis=1)  \n",
    "    # Replace nans with blanks\n",
    "    text_data.fillna('', inplace=True)    \n",
    "    # Join all text items in a row that have a space in between\n",
    "    return text_data.apply(lambda x: \" \".join(x), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "325908    PURCHASED FOOD  SCHOOL NUTRITION SERVICE      ...\n",
       "334752    SALARIES OF PART TIME EMPLOYEE TEACHER LEARNIN...\n",
       "343638    SALARIES OF REGULAR EMPLOYEES  GENERAL FUND Nu...\n",
       "444279    SUPPLIES  PRIMARY GRADES PROGRAM       INSTRUC...\n",
       "66600     ALL OTHER SUPPLEMENTS            TEACHER, THIR...\n",
       "84812     ADDITIONAL/EXTRA DUTY PAY/STIP  ARRA - STIMULU...\n",
       "448545    Personal Services - Other Personnel   PRE-REFE...\n",
       "320496    EMPLOYEE BENEFITS  GENERAL FUND Teacher, Eleme...\n",
       "379967    EMPLOYEE BENEFITS  GENERAL FUND Teacher, Eleme...\n",
       "131671    OTHER SUPPORT PERSONNEL          BUS DRIVER   ...\n",
       "dtype: object"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test it\n",
    "combine_text_columns(df.sample(n=10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add pipeline\n",
    "\n",
    "The tutorial introduces a pipeline to consolidate preprocessing and modeling in a single classifier/estimator and to facilitate experimentation with both preprocessing and different models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build the pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The numeric data is not helpful.\n",
    "\n",
    "Between mod1 and mod3 (mod2 only changes the classifier to RandomForest, leaving preprocessing alone) the changes are:\n",
    "\n",
    "1. tokenize on alphanumeric (instead of default)\n",
    "2. Add bigrams to CountVectorizer (previously was used with default settings).  This doubles the size of the wordvec space.\n",
    "3. Dimension reduction with SelectKBest using chi-squared (300 features)\n",
    "\n",
    "Some things to note about the default CountVectorizer:\n",
    "1) All strings are downcased\n",
    "2) The default setting selects tokens of 2 or more alphanumeric characters (punctuation is completely ignored and always treated as a token separator).  This means single letter or digit tokens are ignored.\n",
    "3) If the vectorizer is used to transform another input (e.g. test), any tokens not in the original corpus are ignored.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### One other way to work around bug exposed with CountVectorizer/OneVsRest/Logistic would be to replace all the numeric values with 0.  The classifiers  should ignore (and might work with n_jobs=-1).\n",
    "\n",
    "Yes, this works well and uses all processors yielding the same results as the slower, 1-processor version above.  Fits in 464 sec instead of 827 sec.\n",
    "\n",
    "##### Note: after some change in sklearn in anaconda update, n_jobs=-1 in OneVsRest causes hang.  Removed all parallelism in those calls."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import FunctionTransformer\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "\n",
    "# Get the dummy encoding of the labels\n",
    "dummy_labels = pd.get_dummies(df[LABELS])\n",
    "\n",
    "# Get the columns that are features in the original df\n",
    "NON_LABELS = [c for c in df.columns if c not in LABELS]\n",
    "\n",
    "# Split into training and test sets\n",
    "X_train, X_test, y_train, y_test = multilabel_train_test_split(df[NON_LABELS],\n",
    "                                                               dummy_labels,\n",
    "                                                               0.2, \n",
    "                                                               seed=123)\n",
    "# Preprocess the text data: get_text_data\n",
    "get_text_data = FunctionTransformer(combine_text_columns, validate=False)\n",
    "\n",
    "# Use all 0s instead of noise: get_numeric_data\n",
    "get_numeric_data_hack = FunctionTransformer(lambda x: np.zeros(x[NUMERIC_COLUMNS].shape, dtype=np.float), validate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit time: 855.26 seconds\n"
     ]
    }
   ],
   "source": [
    "# Complete the pipeline: pl\n",
    "mod_1_1_1 = Pipeline([\n",
    "        ('union', FeatureUnion(\n",
    "            transformer_list = [\n",
    "                ('numeric_features', Pipeline([('selector', get_numeric_data_hack),\n",
    "                                               ('imputer', Imputer())])),\n",
    "                ('text_features', Pipeline([('selector', get_text_data),\n",
    "                                            ('vectorizer', CountVectorizer())]))\n",
    "             ])),\n",
    "        ('clf', OneVsRestClassifier(LogisticRegression()))\n",
    "    ])\n",
    "\n",
    "start = timer()\n",
    "# Fit to the training data\n",
    "mod_1_1_1.fit(X_train, y_train)\n",
    "end = timer()\n",
    "print('fit time: {:0.2f} seconds'.format(end - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predict.proba time: 16.32 seconds\n"
     ]
    }
   ],
   "source": [
    "### For log loss we need the probabilities, not the predicted labels\n",
    "start = timer()\n",
    "mod_1_1_1_yhat_train_probas = mod_1_1_1.predict_proba(X_train)\n",
    "mod_1_1_1_yhat_test_probas = mod_1_1_1.predict_proba(X_test)\n",
    "end = timer()\n",
    "print('Predict.proba time: {:0.2f} seconds'.format(end - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log loss on training set: 0.0874\n",
      "log loss on test set: 0.0940\n"
     ]
    }
   ],
   "source": [
    "print('log loss on training set: {:0.4f}'.format(multi_multi_log_loss(mod_1_1_1_yhat_train_probas, \n",
    "                                                                      y_train.values, BOX_PLOTS_COLUMN_INDICES)))\n",
    "print('log loss on test set: {:0.4f}'.format(multi_multi_log_loss(mod_1_1_1_yhat_test_probas, \n",
    "                                                                      y_test.values, BOX_PLOTS_COLUMN_INDICES)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(y_test.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((80055, 104), (80055, 104))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.values.shape,  mod_1_1_1_yhat_test_probas.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "range(0, 37)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BPCI[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log loss for target Function: 0.169\n",
      "log loss for target Object_Type: 0.062\n",
      "log loss for target Operating_Status: 0.050\n",
      "log loss for target Position_Type: 0.071\n",
      "log loss for target Pre_K: 0.033\n",
      "log loss for target Reporting: 0.093\n",
      "log loss for target Sharing: 0.134\n",
      "log loss for target Student_Type: 0.093\n",
      "log loss for target Use: 0.140\n",
      "Average log_loss for all targets : 0.094\n"
     ]
    }
   ],
   "source": [
    "report_log_loss(y_test.values, mod_1_1_1_yhat_test_probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score for target Function: 0.955\n",
      "F1 score for target Object_Type: 0.984\n",
      "F1 score for target Operating_Status: 0.984\n",
      "F1 score for target Position_Type: 0.982\n",
      "F1 score for target Pre_K: 0.990\n",
      "F1 score for target Reporting: 0.972\n",
      "F1 score for target Sharing: 0.962\n",
      "F1 score for target Student_Type: 0.973\n",
      "F1 score for target Use: 0.961\n",
      "Average F1 score for all targets : 0.974\n"
     ]
    }
   ],
   "source": [
    "report_f1(ftl.flat_to_labels(y_test.values), ftl.flat_to_labels(mod_1_1_1_yhat_test_probas))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score for target Function: 0.955\n",
      "Accuracy score for target Object_Type: 0.984\n",
      "Accuracy score for target Operating_Status: 0.985\n",
      "Accuracy score for target Position_Type: 0.983\n",
      "Accuracy score for target Pre_K: 0.990\n",
      "Accuracy score for target Reporting: 0.973\n",
      "Accuracy score for target Sharing: 0.963\n",
      "Accuracy score for target Student_Type: 0.973\n",
      "Accuracy score for target Use: 0.961\n",
      "Average accuracy score for all targets : 0.974\n"
     ]
    }
   ],
   "source": [
    "report_accuracy(ftl.flat_to_labels(y_test.values), ftl.flat_to_labels(mod_1_1_1_yhat_test_probas))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### =============================== End of mod_1_1_1 ============================================"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__================================ Begin Mod3_1 *(add bigrams)* ==================================__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit time: 1549.78 seconds\n"
     ]
    }
   ],
   "source": [
    "# Complete the pipeline: pl\n",
    "mod3_1 = Pipeline([\n",
    "        ('union', FeatureUnion(\n",
    "            transformer_list = [\n",
    "                ('numeric_features', Pipeline([('selector', get_numeric_data_hack),\n",
    "                                               ('imputer', Imputer())])),\n",
    "                ('text_features', Pipeline([('selector', get_text_data),\n",
    "                                            ('vectorizer', CountVectorizer(ngram_range=(1,2)))]))\n",
    "             ])),\n",
    "        ('clf', OneVsRestClassifier(LogisticRegression()))\n",
    "    ])\n",
    "\n",
    "start = timer()\n",
    "# Fit to the training data\n",
    "mod3_1.fit(X_train, y_train)\n",
    "end = timer()\n",
    "print('fit time: {:0.2f} seconds'.format(end - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predict.proba time: 26.80 seconds\n"
     ]
    }
   ],
   "source": [
    "### For log loss we need the probabilities, not the predicted labels\n",
    "start = timer()\n",
    "mod3_1_yhat_train_probas = mod3_1.predict_proba(X_train)\n",
    "mod3_1_yhat_test_probas = mod3_1.predict_proba(X_test)\n",
    "end = timer()\n",
    "print('Predict.proba time: {:0.2f} seconds'.format(end - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log loss on training set: 0.0467\n",
      "log loss on test set: 0.0573\n"
     ]
    }
   ],
   "source": [
    "print('log loss on training set: {:0.4f}'.format(multi_multi_log_loss(mod3_1_yhat_train_probas, \n",
    "                                                                      y_train.values, BOX_PLOTS_COLUMN_INDICES)))\n",
    "print('log loss on test set: {:0.4f}'.format(multi_multi_log_loss(mod3_1_yhat_test_probas, \n",
    "                                                                      y_test.values, BOX_PLOTS_COLUMN_INDICES)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log loss for target Function: 0.114\n",
      "log loss for target Object_Type: 0.041\n",
      "log loss for target Operating_Status: 0.038\n",
      "log loss for target Position_Type: 0.045\n",
      "log loss for target Pre_K: 0.026\n",
      "log loss for target Reporting: 0.051\n",
      "log loss for target Sharing: 0.069\n",
      "log loss for target Student_Type: 0.055\n",
      "log loss for target Use: 0.077\n",
      "Average log_loss for all targets : 0.057\n"
     ]
    }
   ],
   "source": [
    "report_log_loss(y_test.values, mod3_1_yhat_test_probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score for target Function: 0.965\n",
      "F1 score for target Object_Type: 0.987\n",
      "F1 score for target Operating_Status: 0.987\n",
      "F1 score for target Position_Type: 0.987\n",
      "F1 score for target Pre_K: 0.991\n",
      "F1 score for target Reporting: 0.984\n",
      "F1 score for target Sharing: 0.979\n",
      "F1 score for target Student_Type: 0.981\n",
      "F1 score for target Use: 0.975\n",
      "Average F1 score for all targets : 0.982\n"
     ]
    }
   ],
   "source": [
    "report_f1(ftl.flat_to_labels(y_test.values), ftl.flat_to_labels(mod3_1_yhat_test_probas))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score for target Function: 0.965\n",
      "Accuracy score for target Object_Type: 0.987\n",
      "Accuracy score for target Operating_Status: 0.987\n",
      "Accuracy score for target Position_Type: 0.987\n",
      "Accuracy score for target Pre_K: 0.991\n",
      "Accuracy score for target Reporting: 0.984\n",
      "Accuracy score for target Sharing: 0.979\n",
      "Accuracy score for target Student_Type: 0.981\n",
      "Accuracy score for target Use: 0.975\n",
      "Average accuracy score for all targets : 0.982\n"
     ]
    }
   ],
   "source": [
    "report_accuracy(ftl.flat_to_labels(y_test.values), ftl.flat_to_labels(mod3_1_yhat_test_probas))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Submit this because it's better..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\saus\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:2785: DtypeWarning: Columns (5,11) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict time: 3.2710341340325613 seconds\n"
     ]
    }
   ],
   "source": [
    "# Load the holdout data: holdout\n",
    "### Over here the file is TestData.csv\n",
    "holdout = pd.read_csv('data/TestData.csv', index_col=0)\n",
    "\n",
    "start = timer()\n",
    "# Generate predictions: predictions\n",
    "mod3_1_predictions = mod3_1.predict_proba(holdout)\n",
    "end = timer()\n",
    "print('predict time: {} seconds'.format(end - start))\n",
    "\n",
    "pred_mod3_1 = pd.DataFrame(columns=pd.get_dummies(df[LABELS], prefix_sep='__').columns, \n",
    "                             index=holdout.index,\n",
    "                             data=mod3_1_predictions)\n",
    "\n",
    "pred_mod3_1.to_csv('pred_mod3_1.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Top 10 finish!! 0.6599 on holdout set at Drivendata (previous best 0.6827)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__============================= End Mod3_1 *(add bigrams)* ==================__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add the MaxAbsScaler\n",
    "\n",
    "Speeds things up a small amount but also degrades quality slightly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__===================== Begin Mod3_1a *(add bigrams, add MaxAbs scaler)* ==================__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit time: 1139.97 seconds\n"
     ]
    }
   ],
   "source": [
    "# Complete the pipeline: pl\n",
    "mod3_1a = Pipeline([\n",
    "        ('union', FeatureUnion(\n",
    "            transformer_list = [\n",
    "                ('numeric_features', Pipeline([('selector', get_numeric_data_hack),\n",
    "                                               ('imputer', Imputer())])),\n",
    "                ('text_features', Pipeline([('selector', get_text_data),\n",
    "                                            ('vectorizer', CountVectorizer(ngram_range=(1,2)))]))\n",
    "             ])),\n",
    "        ('scale', MaxAbsScaler()),\n",
    "        ('clf', OneVsRestClassifier(LogisticRegression()))\n",
    "    ])\n",
    "\n",
    "start = timer()\n",
    "# Fit to the training data\n",
    "mod3_1a.fit(X_train, y_train)\n",
    "end = timer()\n",
    "print('fit time: {:0.2f} seconds'.format(end - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predict.proba time: 28.71 seconds\n"
     ]
    }
   ],
   "source": [
    "### For log loss we need the probabilities, not the predicted labels\n",
    "start = timer()\n",
    "mod3_1a_yhat_train_probas = mod3_1a.predict_proba(X_train)\n",
    "mod3_1a_yhat_test_probas = mod3_1a.predict_proba(X_test)\n",
    "end = timer()\n",
    "print('Predict.proba time: {:0.2f} seconds'.format(end - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log loss on training set: 0.0492\n",
      "log loss on test set: 0.0593\n"
     ]
    }
   ],
   "source": [
    "print('log loss on training set: {:0.4f}'.format(multi_multi_log_loss(mod3_1a_yhat_train_probas, \n",
    "                                                                      y_train.values, BOX_PLOTS_COLUMN_INDICES)))\n",
    "print('log loss on test set: {:0.4f}'.format(multi_multi_log_loss(mod3_1a_yhat_test_probas, \n",
    "                                                                      y_test.values, BOX_PLOTS_COLUMN_INDICES)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log loss for target Function: 0.119\n",
      "log loss for target Object_Type: 0.044\n",
      "log loss for target Operating_Status: 0.039\n",
      "log loss for target Position_Type: 0.047\n",
      "log loss for target Pre_K: 0.026\n",
      "log loss for target Reporting: 0.052\n",
      "log loss for target Sharing: 0.070\n",
      "log loss for target Student_Type: 0.056\n",
      "log loss for target Use: 0.080\n",
      "Average log_loss for all targets : 0.059\n"
     ]
    }
   ],
   "source": [
    "report_log_loss(y_test.values, mod3_1a_yhat_test_probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score for target Function: 0.964\n",
      "F1 score for target Object_Type: 0.987\n",
      "F1 score for target Operating_Status: 0.987\n",
      "F1 score for target Position_Type: 0.987\n",
      "F1 score for target Pre_K: 0.991\n",
      "F1 score for target Reporting: 0.984\n",
      "F1 score for target Sharing: 0.979\n",
      "F1 score for target Student_Type: 0.981\n",
      "F1 score for target Use: 0.975\n",
      "Average F1 score for all targets : 0.982\n"
     ]
    }
   ],
   "source": [
    "report_f1(ftl.flat_to_labels(y_test.values), ftl.flat_to_labels(mod3_1a_yhat_test_probas))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score for target Function: 0.965\n",
      "Accuracy score for target Object_Type: 0.987\n",
      "Accuracy score for target Operating_Status: 0.987\n",
      "Accuracy score for target Position_Type: 0.987\n",
      "Accuracy score for target Pre_K: 0.991\n",
      "Accuracy score for target Reporting: 0.984\n",
      "Accuracy score for target Sharing: 0.979\n",
      "Accuracy score for target Student_Type: 0.981\n",
      "Accuracy score for target Use: 0.975\n",
      "Average accuracy score for all targets : 0.982\n"
     ]
    }
   ],
   "source": [
    "report_accuracy(ftl.flat_to_labels(y_test.values), ftl.flat_to_labels(mod3_1a_yhat_test_probas))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Does not score as well on DD site, but it fits faster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\saus\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:2785: DtypeWarning: Columns (5,11) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict time: 2.866064067691241 seconds\n"
     ]
    }
   ],
   "source": [
    "# Load the holdout data: holdout\n",
    "### Over here the file is TestData.csv\n",
    "holdout = pd.read_csv('data/TestData.csv', index_col=0)\n",
    "\n",
    "start = timer()\n",
    "# Generate predictions: predictions\n",
    "mod3_1a_predictions = mod3_1a.predict_proba(holdout)\n",
    "end = timer()\n",
    "print('predict time: {} seconds'.format(end - start))\n",
    "\n",
    "pred_mod3_1a = pd.DataFrame(columns=pd.get_dummies(df[LABELS], prefix_sep='__').columns, \n",
    "                             index=holdout.index,\n",
    "                             data=mod3_1a_predictions)\n",
    "\n",
    "pred_mod3_1a.to_csv('pred_mod3_1a.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__============================= End mod3_1a *(add bigrams/MaxAbsScaler)* ==================__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__===================== Begin Mod3_2 *(reduce features with SelectKBest)* ==================__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now reduce features with SelectKBest, keeping 300 best features (chi$^2$)\n",
    "\n",
    "Twice as fast; much worse predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit time: 900.45 seconds\n"
     ]
    }
   ],
   "source": [
    "# add feature selection\n",
    "\n",
    "from sklearn.feature_selection import chi2, SelectKBest\n",
    "\n",
    "chi_k = 300\n",
    "\n",
    "mod3_2 = Pipeline([\n",
    "        ('union', FeatureUnion(\n",
    "            transformer_list = [\n",
    "                ('numeric_features', Pipeline([('selector', get_numeric_data_hack),\n",
    "                                               ('imputer', Imputer())])),\n",
    "                ('text_features', Pipeline([('selector', get_text_data),\n",
    "                                            ('vectorizer', CountVectorizer(ngram_range=(1,2))),\n",
    "                                            ('reduce', SelectKBest(chi2, chi_k))  ]))\n",
    "             ])),\n",
    "        ('clf', OneVsRestClassifier(LogisticRegression()))\n",
    "    ])\n",
    "\n",
    "start = timer()\n",
    "# Fit to the training data\n",
    "mod3_2.fit(X_train, y_train)\n",
    "end = timer()\n",
    "print('fit time: {:0.2f} seconds'.format(end - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predict.proba time: 22.84 seconds\n"
     ]
    }
   ],
   "source": [
    "### For log loss we need the probabilities, not the predicted labels\n",
    "start = timer()\n",
    "mod3_2_yhat_train_probas = mod3_2.predict_proba(X_train)\n",
    "mod3_2_yhat_test_probas = mod3_2.predict_proba(X_test)\n",
    "end = timer()\n",
    "print('Predict.proba time: {:0.2f} seconds'.format(end - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log loss on training set: 0.3026\n",
      "log loss on training set: 0.3050\n"
     ]
    }
   ],
   "source": [
    "print('log loss on training set: {:0.4f}'.format(multi_multi_log_loss(mod3_2_yhat_train_probas, \n",
    "                                                                      y_train.values, BOX_PLOTS_COLUMN_INDICES)))\n",
    "print('log loss on test set: {:0.4f}'.format(multi_multi_log_loss(mod3_2_yhat_test_probas, \n",
    "                                                                      y_test.values, BOX_PLOTS_COLUMN_INDICES)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log loss for target Function: 0.523\n",
      "log loss for target Object_Type: 0.298\n",
      "log loss for target Operating_Status: 0.136\n",
      "log loss for target Position_Type: 0.316\n",
      "log loss for target Pre_K: 0.097\n",
      "log loss for target Reporting: 0.291\n",
      "log loss for target Sharing: 0.373\n",
      "log loss for target Student_Type: 0.313\n",
      "log loss for target Use: 0.397\n",
      "Average log_loss for all targets : 0.305\n"
     ]
    }
   ],
   "source": [
    "report_log_loss(y_test.values, mod3_2_yhat_test_probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\saus\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score for target Function: 0.845\n",
      "F1 score for target Object_Type: 0.909\n",
      "F1 score for target Operating_Status: 0.952\n",
      "F1 score for target Position_Type: 0.905\n",
      "F1 score for target Pre_K: 0.965\n",
      "F1 score for target Reporting: 0.895\n",
      "F1 score for target Sharing: 0.872\n",
      "F1 score for target Student_Type: 0.897\n",
      "F1 score for target Use: 0.861\n",
      "Average F1 score for all targets : 0.900\n"
     ]
    }
   ],
   "source": [
    "report_f1(ftl.flat_to_labels(y_test.values), ftl.flat_to_labels(mod3_2_yhat_test_probas))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score for target Function: 0.852\n",
      "Accuracy score for target Object_Type: 0.911\n",
      "Accuracy score for target Operating_Status: 0.954\n",
      "Accuracy score for target Position_Type: 0.907\n",
      "Accuracy score for target Pre_K: 0.966\n",
      "Accuracy score for target Reporting: 0.897\n",
      "Accuracy score for target Sharing: 0.877\n",
      "Accuracy score for target Student_Type: 0.899\n",
      "Accuracy score for target Use: 0.866\n",
      "Average accuracy score for all targets : 0.903\n"
     ]
    }
   ],
   "source": [
    "report_accuracy(ftl.flat_to_labels(y_test.values), ftl.flat_to_labels(mod3_2_yhat_test_probas))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results are much worse with this feature selection.   The speed up is not that impressive considering the fit time without SelectKFeatures was 800 sec. and with this scheme we're at 460 sec.\n",
    "\n",
    "It could be because:\n",
    "1. 300 is too few features\n",
    "2. these are the wrong 300 to select.\n",
    "\n",
    "We had something like 3k tokens in the fitted CountVectorizer.  Adding bigrams that takes us to 6k."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__===================== End Mod3_2 *(reduce features with SelectKBest)* ==================__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ===================== Begin Mod3_2a (reduce features with SelectKBest, 3000 best) =================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit time: 1269.22 seconds\n"
     ]
    }
   ],
   "source": [
    "# add feature selection\n",
    "\n",
    "from sklearn.feature_selection import chi2, SelectKBest\n",
    "\n",
    "chi_k = 3000\n",
    "\n",
    "mod3_2a = Pipeline([\n",
    "        ('union', FeatureUnion(\n",
    "            transformer_list = [\n",
    "                ('numeric_features', Pipeline([('selector', get_numeric_data_hack),\n",
    "                                               ('imputer', Imputer())])),\n",
    "                ('text_features', Pipeline([('selector', get_text_data),\n",
    "                                            ('vectorizer', CountVectorizer(ngram_range=(1,2))),\n",
    "                                            ('reduce', SelectKBest(chi2, chi_k))  ]))\n",
    "             ])),\n",
    "        ('clf', OneVsRestClassifier(LogisticRegression()))\n",
    "    ])\n",
    "\n",
    "start = timer()\n",
    "# Fit to the training data\n",
    "mod3_2a.fit(X_train, y_train)\n",
    "end = timer()\n",
    "print('fit time: {:0.2f} seconds'.format(end - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predict.proba time: 24.82 seconds\n"
     ]
    }
   ],
   "source": [
    "### For log loss we need the probabilities, not the predicted labels\n",
    "start = timer()\n",
    "mod3_2a_yhat_train_probas = mod3_2a.predict_proba(X_train)\n",
    "mod3_2a_yhat_test_probas = mod3_2a.predict_proba(X_test)\n",
    "end = timer()\n",
    "print('Predict.proba time: {:0.2f} seconds'.format(end - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log loss on training set: 0.0738\n",
      "log loss on training set: 0.0798\n"
     ]
    }
   ],
   "source": [
    "print('log loss on training set: {:0.4f}'.format(multi_multi_log_loss(mod3_2a_yhat_train_probas, \n",
    "                                                                      y_train.values, BOX_PLOTS_COLUMN_INDICES)))\n",
    "print('log loss on test set: {:0.4f}'.format(multi_multi_log_loss(mod3_2a_yhat_test_probas, \n",
    "                                                                      y_test.values, BOX_PLOTS_COLUMN_INDICES)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log loss for target Function: 0.150\n",
      "log loss for target Object_Type: 0.056\n",
      "log loss for target Operating_Status: 0.049\n",
      "log loss for target Position_Type: 0.067\n",
      "log loss for target Pre_K: 0.034\n",
      "log loss for target Reporting: 0.070\n",
      "log loss for target Sharing: 0.101\n",
      "log loss for target Student_Type: 0.077\n",
      "log loss for target Use: 0.114\n",
      "Average log_loss for all targets : 0.080\n"
     ]
    }
   ],
   "source": [
    "report_log_loss(y_test.values, mod3_2a_yhat_test_probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score for target Function: 0.956\n",
      "F1 score for target Object_Type: 0.983\n",
      "F1 score for target Operating_Status: 0.984\n",
      "F1 score for target Position_Type: 0.981\n",
      "F1 score for target Pre_K: 0.989\n",
      "F1 score for target Reporting: 0.979\n",
      "F1 score for target Sharing: 0.970\n",
      "F1 score for target Student_Type: 0.975\n",
      "F1 score for target Use: 0.965\n",
      "Average F1 score for all targets : 0.976\n"
     ]
    }
   ],
   "source": [
    "report_f1(ftl.flat_to_labels(y_test.values), ftl.flat_to_labels(mod3_2a_yhat_test_probas))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score for target Function: 0.956\n",
      "Accuracy score for target Object_Type: 0.983\n",
      "Accuracy score for target Operating_Status: 0.984\n",
      "Accuracy score for target Position_Type: 0.981\n",
      "Accuracy score for target Pre_K: 0.989\n",
      "Accuracy score for target Reporting: 0.979\n",
      "Accuracy score for target Sharing: 0.970\n",
      "Accuracy score for target Student_Type: 0.975\n",
      "Accuracy score for target Use: 0.965\n",
      "Average accuracy score for all targets : 0.976\n"
     ]
    }
   ],
   "source": [
    "report_accuracy(ftl.flat_to_labels(y_test.values), ftl.flat_to_labels(mod3_2a_yhat_test_probas))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results for 3k features are better than 300, but less good than using all.   Slight speed up.\n",
    "\n",
    "This might be okay for doing sparse interactions.  3000 * 3000 = 9M.  Don't know just how sparse everything will be.  Might run overnight."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ===================== End Mod3_2a (reduce features with SelectKBest, 3000 best) =================="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ===================== Begin Mod3_2b (reduce features with SelectKBest, 15000 best) =================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit time: 1475.92 seconds\n"
     ]
    }
   ],
   "source": [
    "# add feature selection\n",
    "\n",
    "from sklearn.feature_selection import chi2, SelectKBest\n",
    "\n",
    "chi_k = 15000\n",
    "\n",
    "mod3_2b = Pipeline([\n",
    "        ('union', FeatureUnion(\n",
    "            transformer_list = [\n",
    "                ('numeric_features', Pipeline([('selector', get_numeric_data_hack),\n",
    "                                               ('imputer', Imputer())])),\n",
    "                ('text_features', Pipeline([('selector', get_text_data),\n",
    "                                            ('vectorizer', CountVectorizer(ngram_range=(1,2))),\n",
    "                                            ('reduce', SelectKBest(chi2, chi_k))  ]))\n",
    "             ])),\n",
    "        ('clf', OneVsRestClassifier(LogisticRegression()))\n",
    "    ])\n",
    "\n",
    "start = timer()\n",
    "# Fit to the training data\n",
    "mod3_2b.fit(X_train, y_train)\n",
    "end = timer()\n",
    "print('fit time: {:0.2f} seconds'.format(end - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predict.proba time: 24.46 seconds\n"
     ]
    }
   ],
   "source": [
    "### For log loss we need the probabilities, not the predicted labels\n",
    "start = timer()\n",
    "mod3_2b_yhat_train_probas = mod3_2b.predict_proba(X_train)\n",
    "mod3_2b_yhat_test_probas = mod3_2b.predict_proba(X_test)\n",
    "end = timer()\n",
    "print('Predict.proba time: {:0.2f} seconds'.format(end - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log loss on training set: 0.0500\n",
      "log loss on training set: 0.0589\n"
     ]
    }
   ],
   "source": [
    "print('log loss on training set: {:0.4f}'.format(multi_multi_log_loss(mod3_2b_yhat_train_probas, \n",
    "                                                                      y_train.values, BOX_PLOTS_COLUMN_INDICES)))\n",
    "print('log loss on training set: {:0.4f}'.format(multi_multi_log_loss(mod3_2b_yhat_test_probas, \n",
    "                                                                      y_test.values, BOX_PLOTS_COLUMN_INDICES)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log loss for target Function: 0.117\n",
      "log loss for target Object_Type: 0.042\n",
      "log loss for target Operating_Status: 0.039\n",
      "log loss for target Position_Type: 0.046\n",
      "log loss for target Pre_K: 0.027\n",
      "log loss for target Reporting: 0.052\n",
      "log loss for target Sharing: 0.071\n",
      "log loss for target Student_Type: 0.056\n",
      "log loss for target Use: 0.080\n",
      "Average log_loss for all targets : 0.059\n"
     ]
    }
   ],
   "source": [
    "report_log_loss(y_test.values, mod3_2b_yhat_test_probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score for target Function: 0.964\n",
      "F1 score for target Object_Type: 0.987\n",
      "F1 score for target Operating_Status: 0.986\n",
      "F1 score for target Position_Type: 0.987\n",
      "F1 score for target Pre_K: 0.991\n",
      "F1 score for target Reporting: 0.984\n",
      "F1 score for target Sharing: 0.979\n",
      "F1 score for target Student_Type: 0.981\n",
      "F1 score for target Use: 0.975\n",
      "Average F1 score for all targets : 0.982\n"
     ]
    }
   ],
   "source": [
    "report_f1(ftl.flat_to_labels(y_test.values), ftl.flat_to_labels(mod3_2b_yhat_test_probas))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score for target Function: 0.965\n",
      "Accuracy score for target Object_Type: 0.987\n",
      "Accuracy score for target Operating_Status: 0.987\n",
      "Accuracy score for target Position_Type: 0.987\n",
      "Accuracy score for target Pre_K: 0.991\n",
      "Accuracy score for target Reporting: 0.984\n",
      "Accuracy score for target Sharing: 0.979\n",
      "Accuracy score for target Student_Type: 0.981\n",
      "Accuracy score for target Use: 0.975\n",
      "Average accuracy score for all targets : 0.982\n"
     ]
    }
   ],
   "source": [
    "report_accuracy(ftl.flat_to_labels(y_test.values), ftl.flat_to_labels(mod3_2b_yhat_test_probas))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__===================== End Mod3_3 *(reduce features with SelectFromModel)* ==================__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interlude: What about the feature selection?  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### I want to look at the features to see what they are.  But I need to do all the preprocessing first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(pandas.core.frame.DataFrame, (320222, 16))"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We start with X_train; 16 column dataframe\n",
    "type(X_train), X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# then we combine all the columns with function xformer get_text_data\n",
    "orig_texts = combine_text_columns(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Object_Description                        NaN\n",
       "Text_2                                    NaN\n",
       "SubFund_Description                       NaN\n",
       "Job_Title_Description     Teacher-Elementary \n",
       "Text_3                                    NaN\n",
       "Text_4                                    NaN\n",
       "Sub_Object_Description                    NaN\n",
       "Location_Description                      NaN\n",
       "FTE                                         1\n",
       "Function_Description                      NaN\n",
       "Facility_or_Department                    NaN\n",
       "Position_Extra                  KINDERGARTEN \n",
       "Total                                 50471.8\n",
       "Program_Description              KINDERGARTEN\n",
       "Fund_Description                 General Fund\n",
       "Text_1                                    NaN\n",
       "Name: 134338, dtype: object"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.iloc[0, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(pandas.core.series.Series, (320222,))"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pandas series\n",
    "type(orig_texts), orig_texts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'   Teacher-Elementary        KINDERGARTEN  KINDERGARTEN General Fund '"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "orig_texts.values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "v1 = CountVectorizer(ngram_range=(1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 5.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "features = v1.fit_transform(orig_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(scipy.sparse.csr.csr_matrix, (320222, 3619))"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(features), features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['hardware', 'harvard', 'hat', 'hate', 'hats', 'hay', 'hazardous', 'hazmat', 'hb', 'hbsc', 'hd', 'hdc', 'he', 'hea', 'head', 'headstar', 'headstart', 'healt', 'health', 'healthier', 'healthiest', 'healthly', 'healthy', 'healty', 'hear', 'hearing', 'hearings', 'heart', 'heating', 'heavy', 'heights', 'held', 'help', 'helper', 'helpline', 'here', 'hh', 'hhs', 'hi', 'hidden', 'high', 'higher', 'highly', 'highway', 'hire', 'hirin', 'hist', 'history', 'hiv', 'hlth', 'hmn', 'hndcpd', 'hoa', 'hof', 'holding', 'holdings', 'holiday', 'home', 'homebased', 'homebound', 'homegrown', 'homeless', 'homes', 'homework', 'horticulture', 'hospital', 'hospitality', 'hospitals', 'host', 'hosts', 'hour', 'hourly', 'hous', 'house', 'housing', 'hqt', 'hr', 'hris', 'hrly', 'hrs', 'hs', 'hsbc', 'hst', 'hstw', 'hub', 'hubs', 'human', 'humanities', 'humanware', 'hurricane', 'hvac', 'hvy', 'hydronic', 'hygiene', 'ia', 'iaf', 'ib', 'ic', 'id', 'idea']\n"
     ]
    }
   ],
   "source": [
    "print(v1.get_feature_names()[1500:1600])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "v2 = CountVectorizer(ngram_range=(1,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 10.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "features2grams = v2.fit_transform(orig_texts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Interesting: Adding bigrams takes us from 3.6k tokens to 31k features (tokens + bigrams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(scipy.sparse.csr.csr_matrix, (320222, 31010))"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(features2grams), features2grams.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['lep clerical', 'lep computer', 'lep counselor', 'lep critical', 'lep curriculum', 'lep custodian', 'lep extended', 'lep medicare', 'lep miscellaneous', 'lep ninth', 'lep overtime', 'lep regular', 'lep skills', 'lep summer', 'lep teach', 'lep teacher', 'lep temporary', 'lep to', 'lep travel', 'less', 'less than', 'let', 'let me', 'level', 'level chair', 'level dept', 'levy', 'levy admin', 'levy administrator', 'levy asst', 'levy blank', 'levy bookkeeper', 'levy bus', 'levy coordinator', 'levy counter', 'levy credit', 'levy data', 'levy deputy', 'levy dir', 'levy early', 'levy ela', 'levy elementary', 'levy exec', 'levy extended', 'levy facilitator', 'levy general', 'levy health', 'levy helper', 'levy itemge', 'levy itinerant', 'levy library', 'levy maintenance', 'levy manager', 'levy military', 'levy nurse', 'levy office', 'levy opp', 'levy override', 'levy passroom', 'levy pest', 'levy prevent', 'levy principal', 'levy program', 'levy project', 'levy protech', 'levy psychologist', 'levy reading', 'levy school', 'levy secondary', 'levy secretary', 'levy security', 'levy sfpc', 'levy social', 'levy spec', 'levy specialist', 'levy speech', 'levy student', 'levy summer', 'levy supv', 'levy tchr', 'levy teacher', 'levy temporary', 'levy truancy', 'levy truck', 'levy tutor', 'levy youth', 'lfi', 'lfi local', 'lghtng', 'lghtng prjt', 'li', 'li recruit', 'liability', 'liability charges', 'liability insurance', 'liability self', 'liaison', 'liaison admissions', 'liaison alternative', 'liaison bilingual']\n"
     ]
    }
   ],
   "source": [
    "print(v2.get_feature_names()[15000:15100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "est = RandomForestClassifier(n_jobs=-1).fit(features2grams, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4.49656645e-05, 0.00000000e+00, 5.14667071e-09, ...,\n",
       "       5.61730428e-08, 6.42651010e-09, 0.00000000e+00])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "est.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_is_ = est.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(31010,)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f_is_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9999999999999999"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(f_is_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3.224766204450177e-05, 6.45473520818476e-07)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(f_is_), np.median(f_is_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.00013773350387231845"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(f_is_[f_is_ < 0.2 * np.median(f_is_)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\saus\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: RuntimeWarning: divide by zero encountered in log\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x2a98a62cd30>]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(np.log(np.sort(f_is_)))\n",
    "plt.plot(np.array([0, 30000]), np.ones(2) * np.log(np.mean(f_is_)))\n",
    "plt.plot(np.array([0, 30000]), np.ones(2) * np.log(np.median(f_is_)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__===================== Begin Mod3_3 *(reduce features with SelectFromModel)* ==================__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now put the selector in the pipeline....\n",
    "\n",
    "This is going to be slow because it has to fit two models, the RF for feature importance and then the OneVsRest(Logistic..()).  \n",
    "\n",
    "I think it's going to end up using 15k features by kicking out everything of less than median importance).  That's still a __lot__ of features.  But I did use them all previously (800 sec, I think).\n",
    "\n",
    "It's very nearly as good but ends up taking 50% longer than using the whole feature set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit time: 2124.54 seconds\n"
     ]
    }
   ],
   "source": [
    "mod3_3 = Pipeline([\n",
    "        ('union', FeatureUnion(\n",
    "            transformer_list = [\n",
    "                ('numeric_features', Pipeline([('selector', get_numeric_data_hack),\n",
    "                                               ('imputer', Imputer())])),\n",
    "                ('text_features', Pipeline([('selector', get_text_data),\n",
    "                                            ('vectorizer', CountVectorizer(ngram_range=(1,2))),\n",
    "                                            ('reduce', SelectFromModel(RandomForestClassifier(n_jobs=-1), \n",
    "                                                                       threshold='median')) ] ) )\n",
    "             ])),\n",
    "        ('clf', OneVsRestClassifier(LogisticRegression()))\n",
    "    ])\n",
    "\n",
    "start = timer()\n",
    "# Fit to the training data\n",
    "mod3_3.fit(X_train, y_train)\n",
    "end = timer()\n",
    "print('fit time: {:0.2f} seconds'.format(end - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predict.proba time: 27.24 seconds\n"
     ]
    }
   ],
   "source": [
    "### For log loss we need the probabilities, not the predicted labels\n",
    "start = timer()\n",
    "mod3_3_yhat_train_probas = mod3_3.predict_proba(X_train)\n",
    "mod3_3_yhat_test_probas = mod3_3.predict_proba(X_test)\n",
    "end = timer()\n",
    "print('Predict.proba time: {:0.2f} seconds'.format(end - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log loss on training set: 0.0481\n",
      "log loss on test set: 0.0580\n"
     ]
    }
   ],
   "source": [
    "print('log loss on training set: {:0.4f}'.format(multi_multi_log_loss(mod3_3_yhat_train_probas, \n",
    "                                                                      y_train.values, BOX_PLOTS_COLUMN_INDICES)))\n",
    "print('log loss on test set: {:0.4f}'.format(multi_multi_log_loss(mod3_3_yhat_test_probas, \n",
    "                                                                      y_test.values, BOX_PLOTS_COLUMN_INDICES)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log loss for target Function: 0.116\n",
      "log loss for target Object_Type: 0.041\n",
      "log loss for target Operating_Status: 0.039\n",
      "log loss for target Position_Type: 0.045\n",
      "log loss for target Pre_K: 0.026\n",
      "log loss for target Reporting: 0.051\n",
      "log loss for target Sharing: 0.070\n",
      "log loss for target Student_Type: 0.055\n",
      "log loss for target Use: 0.079\n",
      "Average log_loss for all targets : 0.058\n"
     ]
    }
   ],
   "source": [
    "report_log_loss(y_test.values, mod3_3_yhat_test_probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score for target Function: 0.965\n",
      "F1 score for target Object_Type: 0.987\n",
      "F1 score for target Operating_Status: 0.987\n",
      "F1 score for target Position_Type: 0.987\n",
      "F1 score for target Pre_K: 0.991\n",
      "F1 score for target Reporting: 0.984\n",
      "F1 score for target Sharing: 0.979\n",
      "F1 score for target Student_Type: 0.981\n",
      "F1 score for target Use: 0.975\n",
      "Average F1 score for all targets : 0.982\n"
     ]
    }
   ],
   "source": [
    "report_f1(ftl.flat_to_labels(y_test.values), ftl.flat_to_labels(mod3_3_yhat_test_probas))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score for target Function: 0.965\n",
      "Accuracy score for target Object_Type: 0.987\n",
      "Accuracy score for target Operating_Status: 0.987\n",
      "Accuracy score for target Position_Type: 0.987\n",
      "Accuracy score for target Pre_K: 0.991\n",
      "Accuracy score for target Reporting: 0.984\n",
      "Accuracy score for target Sharing: 0.979\n",
      "Accuracy score for target Student_Type: 0.981\n",
      "Accuracy score for target Use: 0.975\n",
      "Average accuracy score for all targets : 0.982\n"
     ]
    }
   ],
   "source": [
    "report_accuracy(ftl.flat_to_labels(y_test.values), ftl.flat_to_labels(mod3_3_yhat_test_probas))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__===================== End Mod3_3 *(reduce features with SelectFromModel)*  ==================__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interlude: model persistence - mod3_3 won't pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A subdirectory or file model_store already exists.\n"
     ]
    }
   ],
   "source": [
    "!mkdir model_store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "### PicklingError: Can't pickle <function <lambda> at 0x000002236E61DEA0>: attribute lookup <lambda> on __main__ failed\n",
    "#import pickle\n",
    "#saved_model = pickle.dumps(mod3_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "### This fails with a pickling error maybe have to import pickle first\n",
    "# from sklearn.externals import joblib\n",
    "# joblib.dump(mod3_3,'./model_store/fitted_mod3_3.pkl') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This isn't the way to do this.  It ends up almost as good but much, much slower."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### just for yucks let's use L1 penalty in the LogReg.  It may null out different features for different labels.   Don't think it will take too long to run.  C=0.8 is not too much regularization.    We were at 800 sec before.  If this works like I think, it should go a bit faster, but hopefully won't add much bias (we're not overfitted).\n",
    "\n",
    "Completely wrong.  Took 1900 seconds (more than double).  Maybe it has to calculate the regularization and multiply it and that's got to be at least twice the math work)...\n",
    "\n",
    "### Run this again when time allows with C=0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Complete the pipeline: pl\n",
    "# mod3_1L1 = Pipeline([\n",
    "#         ('union', FeatureUnion(\n",
    "#             transformer_list = [\n",
    "#                 ('numeric_features', Pipeline([('selector', get_numeric_data_hack),\n",
    "#                                                ('imputer', Imputer())])),\n",
    "#                 ('text_features', Pipeline([('selector', get_text_data),\n",
    "#                                             ('vectorizer', CountVectorizer(ngram_range=(1,2)))]))\n",
    "#              ])),\n",
    "#         ('clf', OneVsRestClassifier(LogisticRegression(penalty='l1', C=0.8), n_jobs=-1))\n",
    "#     ])\n",
    "\n",
    "# start = timer()\n",
    "# # Fit to the training data\n",
    "# mod3_1L1.fit(X_train, y_train)\n",
    "# end = timer()\n",
    "# print('fit time: {:0.2f} seconds'.format(end - start))\n",
    "\n",
    "# fit time: 1908.42 seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "### For log loss we need the probabilities, not the predicted labels\n",
    "# start = timer()\n",
    "# mod3_1L1_yhat_train_probas = mod3_1L1.predict_proba(X_train)\n",
    "# mod3_1L1_yhat_test_probas = mod3_1L1.predict_proba(X_test)\n",
    "# end = timer()\n",
    "# print('Predict.proba time: {:0.2f} seconds'.format(end - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# print('log loss on training set: {:0.4f}'.format(multi_multi_log_loss(mod3_1L1_yhat_train_probas, \n",
    "#                                                                       y_train.values, BOX_PLOTS_COLUMN_INDICES)))\n",
    "# print('log loss on training set: {:0.4f}'.format(multi_multi_log_loss(mod3_1L1_yhat_test_probas, \n",
    "#                                                                       y_test.values, BOX_PLOTS_COLUMN_INDICES)))\n",
    "# log loss on training set: 0.0511\n",
    "# log loss on training set: 0.0588"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# report_f1(ftl.flat_to_labels(y_test.values), ftl.flat_to_labels(mod3_1L1_yhat_test_probas))\n",
    "# F1 score for target Function: 0.964\n",
    "# F1 score for target Object_Type: 0.987\n",
    "# F1 score for target Operating_Status: 0.987\n",
    "# F1 score for target Position_Type: 0.987\n",
    "# F1 score for target Pre_K: 0.991\n",
    "# F1 score for target Reporting: 0.984\n",
    "# F1 score for target Sharing: 0.979\n",
    "# F1 score for target Student_Type: 0.981\n",
    "# F1 score for target Use: 0.975\n",
    "# Average F1 score for all targets : 0.982"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# report_accuracy(ftl.flat_to_labels(y_test.values), ftl.flat_to_labels(mod3_1L1_yhat_test_probas))\n",
    "# Accuracy score for target Function: 0.965\n",
    "# Accuracy score for target Object_Type: 0.987\n",
    "# Accuracy score for target Operating_Status: 0.987\n",
    "# Accuracy score for target Position_Type: 0.987\n",
    "# Accuracy score for target Pre_K: 0.991\n",
    "# Accuracy score for target Reporting: 0.984\n",
    "# Accuracy score for target Sharing: 0.979\n",
    "# Accuracy score for target Student_Type: 0.981\n",
    "# Accuracy score for target Use: 0.975\n",
    "# Average accuracy score for all targets : 0.982\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
